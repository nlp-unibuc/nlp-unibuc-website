Title: Machine Translation Hungarian to Romanian
Slug: machine_translation/22_23/hu_ro



<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Machine Translation Hungarian to Romanian 1st Semester of 2022-2023</title>
<!--Generated by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->

<link rel="stylesheet" href="LaTeXML.css" type="text/css">
<link rel="stylesheet" href="ltx-article.css" type="text/css">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link rel="stylesheet" href="normalize.css" type="text/css">
<link rel="stylesheet" href="mt_papers.css" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js?config=MML_HTMLorMML"></script>
<script src="mt_toc.js"></script>
</head>
<body>



<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S1" title="1 Introduction ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S2" title="2 Related work ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S3" title="3 Approach ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Approach</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS1" title="3.1 Translation using a convolutional sequence to sequence network conv-seq-2-seq-learning ‣ 3 Approach ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Translation using a convolutional sequence to sequence network <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_ref">conv-seq-2-seq-learning </span></cite></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS2" title="3.2 Translation using the MarianMT transformer model ‣ 3 Approach ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Translation using the MarianMT transformer model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S3.SS3" title="3.3 Translation using a pivot language Transformer model ‣ 3 Approach ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Translation using a pivot language Transformer model</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S4" title="4 Results ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S5" title="5 Comparing with online translation tools ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Comparing with online translation tools</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S6" title="6 Limitations ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S7" title="7 Conclusions and Future Work ‣ Machine Translation Hungarian to Romanian 1st Semester of 2022-2023" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions and Future Work</span></a></li>
</ol></nav>
</nav>

<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:90%;">
<span class="ltx_text" style="font-size:111%;">Machine Translation Hungarian to Romanian
 
<br class="ltx_break"> 
<br class="ltx_break"></span>1st Semester of 2022-2023</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dumitrescu Teodor 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">teodor.dumitrescu</span> 
<br class="ltx_break">Sava Daniel 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">vasile.sava</span> 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter">@s.unibuc.ro</span>
</span></span>
</div>







<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
    
<p class="ltx_p">The aim of our project is to provide the first open-source Hungarian-Romanian machine translation model that is available on the largest NLP open-source community, HuggingFace. This paper details the approaches we tried, the models we trained, how we evaluated their outputs as well as a discussion on how our models compare to Google Translate and other popular translation tools such as Deepl. We also talk about the limitations that we faced and what changes would provide the most significant improvements.</p>
  
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Machine Translation is one of the fundamental subdomains of Natural Language Processing. Since English is so popular in today’s world, especially on the internet, we use translation tools almost everyday, whether we want to be sure about the translation of a specific word or because we want to make sure our new Tweet is grammatically correct so that we won’t be attacked by keyboard warriors. Today, translation tools are very accurate and we can usually rely on their output. Even though it’s not perfect, most of the time it is enough to make yourself understood in another language. This is all great, however, most of the translation tools available are not open source: we don’t know what Machine Learning model they use, on what dataset they are trained, what solutions are used in order to improve their predictions and so on. For us, they are black boxes. We can give them an input and hope that the output is good enough.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">There are some open source communities/projects that provide pretrained models for users to experiment with or finetune. The datasets on which they were trained, the hyperparameters and the results on some benchmark datasets are also provided. One of the most popular open source NLP communities is HuggingFace. They provide lots of models/datasets for different tasks. For Machine Translation, there are many models available and anyone can train/finetune a model and then release it to the public.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">However, even on HuggingFace (and pretty much anywhere else, to the best of our knowledge) there is no open source model that translates Hungarian to Romanian. With this project, we wanted to change that.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">In short, the approach that we used is as follows: we found a <a href="https://www.kaggle.com/datasets/hgultekin/paralel-translation-corpus-in-22-languages" title="" class="ltx_ref ltx_href">dataset</a> of legal documents that contains Hu-Ro bitexts. We trained models from scratch on the dataset and compared them. We also evaluated some pretrained models with the pivot approach (one model for Hu-En plus one for En-Ro, for example) and compared them with our models. We then analysed the outputs of different models for the same input, including some private models, like the ones used by Google Translate and Deepl and talked about the key differences between them.
<br class="ltx_break"></p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">Contributions:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Teodor: researched datasets available, cleaned the DGT dataset (the one that we chose for the project), researched and trained MarianMT transformer model from scratch with the HuggingFace library. Uploaded the best transformer model on HuggingFace. Uploaded the cleaned DGT dataset to HuggingFace. Contributed to this paper as well as the presentation.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Daniel: researched datasets available, worked on cleaning another <a href="https://live.european-language-grid.eu/catalogue/corpus/19660" title="" class="ltx_ref ltx_href">dataset</a> before we switched to DGT. Researched and evaluated pretrained models with the pivoting approach (English, French and Finnish), trained CNN models from scratch with the fairseq library. Tried to combine the encoder of a Hu-X model with the decoder of a X-Ro model. Contributed to this paper as well as the presentation.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">We chose to approach this project because we wanted to code ourselves a solution for Machine Translation with a pair of languages and see how it works and how difficult it is. We picked this pair because they are unpopular languages, there is not much research available therefore it was an opportunity of having a lot of impact (first open source Hu-Ro model on HuggingFace). Also, very importantly, there are a lot of Hungarians living in Romania. We believe that advancing the state of the art (or at least encouraging other people to do research in this direction) would benefit them.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">We didn’t find research publicly available for Hu-Ro translation. Also, even though a lot of less popular language pairs have models available on HuggingFace, there is none for Hu-Ro. There are models for Hu-Fi and Fi-Ro, or Hu-En and En-Ro, and we used such models with the pivoting approach in order to compare them with our models. These models were provided by the organization Helsinki-NLP. They have trained MarianMT for a lot of language pairs and have uploaded about 1000 models to the HuggingFace Hub. We could say that we tried what worked on other language pairs because chances were that it would work on ours too. For example, Teodor used the configuration of MarianMT for En-Ro with some minor changes (vocabulary size and special tokens), but for Hu-Ro. 
<br class="ltx_break"></p>
</div>

</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">The goal of machine translation is to create automatic systems that can translate content from one language (the source) to another (the destination) without the assistance of a person. There are several kinds of solutions depending on their complexity (and effectiveness), each with advantages and disadvantages: Rule-Based Machine Translation (RBMT), Statistical Machine Translation (SMT), and Neural Machine Translation (NMT).</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">The first category involves rule-based techniques based on the grammars of the language by substituting each word for its translation in the location specified by the grammar rules. Despite having a nice theoretical foundation, it has been found to be incredibly ineffective in reality, particularly when it comes to determining the optimum adaptive rule for a pair of sentences and how complicated and varied grammatical rules should be. There is also the issue of conflicting rules already in place. Because Romanian and Hungarian are not part of the same family language, identifying a Rule-Based Machine Translation system would be a very challenging effort.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">Until the Deep Learning revolution (about 2010), the most well-known approach was Statistical Machine Translation. These models used statistics to identify related words and phrases in a parallel / bilingual corpus. The most popular variant is phrase-based SMT, which allows for more accurate translations than the original word-to-word translation presented above. It does this by mapping phrases from the source language with phrases from the destination language. Although this method provides better translations, it still has problems with long-term dependencies (e.g. incorrect gender agreements).</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">Today, the most well-established method for tackling Machine Translation issues is the encoder-decoder framework, which is based on deep learning and which falls under the last category. It consists of two distinct components, which are both of a similar kind. A raw sentence (often in the form of a list of words) is converted into a fixed-sized and dense representation using an encoder. The decoder takes the latter and begins anticipating a translation word by word until it obtains a specific token, which is often used to indicate the conclusion of a phrase. The output of the encoder and its own previously anticipated words are both available to the decoder at any one time.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Approach</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Translation using a convolutional sequence to sequence network <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib8" title="" class="ltx_ref">conv-seq-2-seq-learning </a></cite>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">Such a network consists of a fully convolutional encoder and a fully convolutional decoder, where each is followed by a non-linear layer. At training time, the outputs generated by the encoder and decoder are pushed to a dot product in order to determine the actual attention values <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib3" title="" class="ltx_ref">CNN-seq-2-seq </a></cite>. The calculated dot product is then added together with the decoder result to (successfully) predict the target words.
</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="hu_ro/seq2seq-cnn.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="646" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Convolutional sequence to sequence architecture</figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">Using SentencePiece encoding we have trained the model for 11 epochs (<math id="S3.SS1.p2.m1" class="ltx_Math" alttext="\sim" display="inline"><mo>∼</mo></math> 13 hours including validation steps) on an NVIDIA T4 GPU. As far as hyperparameters are concerned we have chosen to use a learning rate of 0.5 (due to the hasty training for such a complex model) and label smoothing, which ensures the regularization at training time, by introducing noise to labels, which in turn results to a decreased overfitting chance. During training time the loss has steadily decreased for the first 6 epochs, after which it started to stagnate at around <math id="S3.SS1.p2.m2" class="ltx_Math" alttext="3.25" display="inline"><mn>3.25</mn></math>. The whole process was made possible using <a href="https://fairseq.readthedocs.io" title="" class="ltx_ref ltx_href">FairSeq’s CLI</a>.
Support code can be accessed at this <a href="https://colab.research.google.com/drive/1R8q2kPOFbz1VSpt6nvXDUVxjCny7jP_A?usp=sharing" title="" class="ltx_ref ltx_href">link</a></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Translation using the MarianMT transformer model</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">For most NLP tasks today, transformer models are by far the number one choice. Machine Translation is no exception. Choosing to focus mostly on transformer models was a no-brainer, since they were most likely to perform well but also since Hugging Face is designed as an open source hub for transformer models.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">Our transformer of choice is MarianMT <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">MarianMt </a></cite> since it is specifically designed for the task of Machine Translation. Also, it is relatively small compared to other transformer models, with around 50 million trainable parameters, depending on vocabulary size. Additionally, at the time of writing this paper, out of 1,854 models uploaded on Hugging Face for the task of translation, 1,446 are MarianMT models trained by the organization Helsinki-NLP. We tought that if it worked for so many language pairs, it might work for Hu-Ro as well.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="hu_ro/transformer.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="598" height="893" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Transformer Encoder-Decoder architecture</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p">MarianMT is a transformer model with the encoder-decoder architecture. We didn’t experiment with architecture parameters since we had time and resources limitations. We used the same values that Helsinki-NLP used for their En-Ro model, apart from the vocabulary size.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p class="ltx_p">Architecture parameters:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Encoder/Decoder layers: 6
</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Encoder/Decore attention heads: 8</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p class="ltx_p">Vocabulary size: 10,000 and 20,000. (different models)</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p class="ltx_p">Number of beams for Beam Search: 4</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Translation using a pivot language Transformer model</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">Machine Translation research is biased towards language pairs including English due to the ease of collecting parallel corpora. Translation between non-English languages, e.g., Hungarian to Romanian, is usually done with pivoting through English <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib5" title="" class="ltx_ref">pivot-translation </a></cite>, i.e., translating Hungarian (source) input to English (pivot) first with a Hungarian to English model which is later translated to Romanian (target) with a English to Romanian model. The most naive approach is reusing (already trained) source to pivot and pivot to target models directly, decoding twice via the pivot language.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p">As presented earlier, because there is no model to translate directly from Hungarian to Romanian, we used two different models with the same architecture, namely the MarianMT model, an encoder-decoder transformer with six layers in each component. All the used models (HU to pivot and pivot to RO) were pretrained by Helsinki-NLP. Regarding the pivot, we’ve tried several: English (EN), French (FR), and Finnish (FI). However, this approach requires doubled decoding time and the translation errors are propagated or expanded via the two-step process. Therefore, it is more beneficial to build a single source to target model directly for both efficiency and adequacy <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib6" title="" class="ltx_ref">pivot-translation-2 </a></cite>. We tried to combine the Hungarian to pivot encoder with the pivot to Romanian decoder, but we couldn’t make it work because of the architecture. More exactly, MarianMT uses a shared embeddings layer, which has the size of the vocabulary. As the vocabularies for the models are different, this layer is different, therefore we can’t merge these components.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">We have used two different metrics to evaluate our models:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">BLEU</span> (Bilingual Evaluation Understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. Quality is considered to be the correspondence between a machine’s output and that of a human: "the closer a machine translation is to a professional human translation, the better it is" - this is the central idea behind BLEU. BLEU was one of the first metrics to claim a high correlation with human judgements of quality, and remains one of the most popular automated and inexpensive metrics.</p>
</div>
<div id="S4.I1.i1.p2" class="ltx_para">
<p class="ltx_p">Scores are calculated for individual translated segments - generally sentences - by comparing them with a set of good quality reference translations. Those scores are then averaged over the whole corpus to reach an estimate of the translation’s overall quality. Neither intelligibility nor grammatical correctness are not taken into account.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">BERTScore</span> leverages the pre-trained contextual embeddings from BERT and matches words in candidate and reference sentences by cosine similarity. It has been shown to correlate with human judgment on sentence-level and system-level evaluation. Moreover, BERTScore computes precision, recall, and F1 measure, which can be useful for evaluating different language generation tasks. The original BERTScore paper <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib9" title="" class="ltx_ref">bert-score </a></cite> showed that BERTScore correlates well with human judgment on sentence-level and system-level evaluation, but this depends on the model and language pair selected.
Currently, the best model is <span class="ltx_text ltx_font_italic">microsoft/deberta-xlarge-mnli</span> and it should be used instead of the default <span class="ltx_text ltx_font_italic">roberta-large</span> in order to have the best correlation with human evaluation.</p>
</div>
</li>
</ol>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">We have tested our models on two different datasets:</p>
<ol id="S4.I2" class="ltx_enumerate">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p">DGT-TM. This is the dataset that we trained on. We randomly sampled 1,000 examples that the model didn’t see during training and predicted on them. Here we notice that the performance of the models that we trained is close to the performance of pretrained models used with the pivot approach. MarianMT performs significantly worse than the CNN trained with fairseq, judging by the BLEU score. We think that this is because MarianMT requires more training (something that we were not able to provide) in order to perform at its true potential.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p">FLORES. This is a different dataset, it is not legal specific. The data is considerably different from the data that the model saw during training. Here, all the models trained by us perform much worse than the pretrained ones used with the pivot approach. We believe this is because the pivot models were trained on more diverse data (not just legal) therefore they are able to generalize better to non-legal data.</p>
</div>
</li>
</ol>
</div>
<figure id="S4.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">BLEU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">BERTScore</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">MarianMT 10K</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.30366</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.80587</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">MarianMT 20K</td>
<td class="ltx_td ltx_align_center">0.32098</td>
<td class="ltx_td ltx_align_center">0.80756</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">FairSeq 10K</td>
<td class="ltx_td ltx_align_center">0.37789</td>
<td class="ltx_td ltx_align_center">0.82108</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">EN</td>
<td class="ltx_td ltx_align_center">0.39906</td>
<td class="ltx_td ltx_align_center">0.83891</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">FR</td>
<td class="ltx_td ltx_align_center">0.41799</td>
<td class="ltx_td ltx_align_center">0.84285</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b">FI</td>
<td class="ltx_td ltx_align_center ltx_border_b">0.36026</td>
<td class="ltx_td ltx_align_center ltx_border_b">0.82733</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results for DGT-1K</figcaption>
</figure>
<figure id="S4.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">BLEU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span class="ltx_text ltx_font_bold">BERTScore</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t">MarianMT 10K</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.06546</td>
<td class="ltx_td ltx_align_center ltx_border_t">0.70479</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">MarianMT 20K</td>
<td class="ltx_td ltx_align_center">0.07373</td>
<td class="ltx_td ltx_align_center">0.70905</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">FairSeq 10K</td>
<td class="ltx_td ltx_align_center">0.09239</td>
<td class="ltx_td ltx_align_center">0.71035</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">EN</td>
<td class="ltx_td ltx_align_center">0.20930</td>
<td class="ltx_td ltx_align_center">0.80663</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">FR</td>
<td class="ltx_td ltx_align_center">0.18222</td>
<td class="ltx_td ltx_align_center">0.79673</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b">FI</td>
<td class="ltx_td ltx_align_center ltx_border_b">0.14829</td>
<td class="ltx_td ltx_align_center ltx_border_b">0.78027</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results for FLORES</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">First off, it’s noteworthy to observe that experimenting with the pivot language provide various, sometimes better, results. For the DGT-1K corpus, the closeness between French and Romanian and the fact that they are both members of the Latin language family may make it simpler to produce better intermediary translations so that more meaning is captured before converting to Hungarian account for the difference.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">Regarding the FLORES dataset, the results are a bit different. In this case, the model with the English pivot performed the best. A possible cause for this is the diversity of the dataset.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Comparing with online translation tools</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">In this section we will take 3 Hungarian sentences and look at how our MarianMT <cite class="ltx_cite ltx_citemacro_cite"><a href="#bib.bib1" title="" class="ltx_ref">MarianMt </a></cite> and CNN models translate them compared to the English pivot approach, Google Translate and <a href="https://www.deepl.com/translator" title="" class="ltx_ref ltx_href">Deepl</a>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sentence 1:</span> 
<br class="ltx_break">HU: A VIIa. melléklet e rendelet mellékletének megfelelően módosul.
<br class="ltx_break">RO: Anexa VII a se modifică în conformitate cu anexa la prezentul regulament.
<br class="ltx_break"></p>
</div>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p">Translations:</p>
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Google: VIIa. anexa se modifica in conformitate cu anexa la prezentul regulament.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Deepl: Anexa VIIa se modifică în conformitate cu anexa la prezentul regulament.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p class="ltx_p">MarianMT: Anexa VIIa se modifică în conformitate cu anexa la prezentul regulament.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p class="ltx_p">CNN: Anexa VIIa se modifică în conformitate cu anexa la prezentul regulament.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p class="ltx_p">En pivot: Anexa VIIa se modifică în conformitate cu anexa la prezentul regulament.</p>
</div>
</li>
</ol>
</div>
<div id="S5.p4" class="ltx_para">
<p class="ltx_p">We notice that all models translate the sentence perfectly, apart from Google Translate. However, Google only switches the places of the first two words.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sentence 2:</span> 
<br class="ltx_break">HU: A relatív válaszjel faktor meghatározására szolgáló oldat.
<br class="ltx_break">RO: Solutie pentru determinarea factorului de răspuns relativ.
<br class="ltx_break"></p>
</div>
<div id="S5.p6" class="ltx_para">
<p class="ltx_p">Translations:</p>
<ol id="S5.I2" class="ltx_enumerate">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p class="ltx_p">Google: Solutie pentru determinarea factorului de semnal de răspuns relativ.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p class="ltx_p">Deepl: Solutie pentru determinarea factorului de răspuns relativ.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p class="ltx_p">MarianMT: Solutie de determinare a corespondentei relative.</p>
</div>
</li>
<li id="S5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I2.i4.p1" class="ltx_para">
<p class="ltx_p">CNN: Solutie de determinare a factorului de răspuns relativ.</p>
</div>
</li>
<li id="S5.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I2.i5.p1" class="ltx_para">
<p class="ltx_p">En pivot: Soluţie pentru determinarea factorului de răspuns relativ.</p>
</div>
</li>
</ol>
</div>
<div id="S5.p7" class="ltx_para">
<p class="ltx_p">Here we notice that Deepl and the En pivot translate the sentence perfectly. Google adds an additional word "de semnal". The CNN uses "de" instead of "pentru" which is a negligible issue, while MarianMT also replaces "factorului de raspuns" with "corespondentei", therefore its translation is considerably worse compared to all other approaches, but the meaning of the sentence is largely preserved.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sentence 3:</span> 
<br class="ltx_break">HU: A Crédit Mutuel az ügy elhúzódását rója fel a Bizottságnak.
<br class="ltx_break">RO: Crédit Mutuel reprosează Comisiei durata extrem de îndelungată de solutionare a cauzei.
<br class="ltx_break"></p>
</div>
<div id="S5.p9" class="ltx_para">
<p class="ltx_p">Translations:</p>
<ol id="S5.I3" class="ltx_enumerate">
<li id="S5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I3.i1.p1" class="ltx_para">
<p class="ltx_p">Google: Crédit Mutuel acuză Comisia că a amânat cazul.</p>
</div>
</li>
<li id="S5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I3.i2.p1" class="ltx_para">
<p class="ltx_p">Deepl: Crédit Mutuel dă vina pe Comisie pentru această întârziere.</p>
</div>
</li>
<li id="S5.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I3.i3.p1" class="ltx_para">
<p class="ltx_p">MarianMT: Initutia Crédit Mutuel este obligată Comisiei să retragă retragarea cauzei.</p>
</div>
</li>
<li id="S5.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I3.i4.p1" class="ltx_para">
<p class="ltx_p">CNN: Crédit Mutuel îsi dă acordul cu privire la acest aspect.</p>
</div>
</li>
<li id="S5.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S5.I3.i5.p1" class="ltx_para">
<p class="ltx_p">En pivot: Crédit Mutuel dă vina pe Comisie pentru întârzierea cazului.</p>
</div>
</li>
</ol>
</div>
<div id="S5.p10" class="ltx_para">
<p class="ltx_p">Here we see that Deepl, Google and En pivot keep the sense of the sentence mostly intact, but rephrase it. MarianMT and the CNN on the other hand perform very poorly on this particular sentence. MarianMT in particular produces two words that are grammatically incorrect: "Initutia" and "retragarea".
<br class="ltx_break"></p>
</div>
<div id="S5.p11" class="ltx_para">
<p class="ltx_p">We see that there is still space for improvement. We believe that training MarianMT on a larger dataset (we used only 400,000 bitexts) and for more epochs (we trained for 10 epochs) would significantly improve its performance. A hint for this is the fact that the training loss was still decreasing significantly even after the 10th epoch.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">Given the fact that we had access to limited free resources and time to research/train, we naturally encountered a lot of limitations. Also, the models that we trained have some corpus specific limitations worth mentioning. We will now list the key issues of our work/approach:</p>
</div>
<div id="S6.p2" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p class="ltx_p">GPU: we have used Google Colab for all our training/experiments. The machine that we had at our disposal had 12 GB RAM and a Tesla T4 GPU with 15GB VRAM. The maximum batch size that we were able to use with MarianMT was 64, but only if we did no evaluation while training. Still, the training took about 45 minutes per epoch. We were able to train for a few hours before Colab would kick us out for using the GPU for too long. Then we had to wait for almost a whole day to have access to the GPU again. This slowed us down and didn’t allow us to train for a long time (and Transformers are known to require a lot of training).
</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Time: we wanted to try multiple models with multiple vocab sizes and then compare them. However, we quickly realised that in order to do that, we need to train only on a small portion of the whole DGT-TM corpus, because with only one GPU and limited access to it, it would take us until the exam session of the next semester to actually have some results. Therefore, we used only 400,000 out of all 2,180,266 bitexts in the dataset for training. For testing, we used only 1,000 examples since at test time models use beam search to generate output and it takes about 30 minutes to predict on 1,000 examples.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p class="ltx_p">Dataset: we chose to train on DGT-TM, a corpus of European Union laws translated in over 20 languages, among which Hungarian and Romanian. Most of the texts are aligned pretty well. However, there are some with really poor alignment (we didn’t correct their alignment, that would be perhaps an entirely different task). Also we found examples in french and examples that simply were missing some words. We tried our best to filter some of examples that were unlikely to help our models: examples shorter than 3 words, examples that are 3 times (or more) larger in one language than in the other and empty examples.</p>
</div>
</li>
<li id="S6.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i4.p1" class="ltx_para">
<p class="ltx_p">Domain: we chose to train on a legal corpus, therefore our models do pretty well on legal specific data. If we evaluate them on other datasets that are not legal specific, they perform pretty poorly, as we can see from the results on FLORES.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions and Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p">We believe that we have achieved our main goal: making a Hu-Ro translation model publicly available. The model can be downloaded from Hugging Face hub and anyone can use it directly from the Hugging Face UI at the following <a href="https://huggingface.co/Bucharest-NLP/dgt-mt-hu-ro" title="" class="ltx_ref ltx_href">link</a>.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p class="ltx_p">There are however things that can be improved. We believe that there are three main steps that would greatly benefit the project, in the future:</p>
</div>
<div id="S7.p3" class="ltx_para">
<ol id="S7.I1" class="ltx_enumerate">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Use a machine with multiple GPUs that allows for continuous training for a long time (weeks). This way, the whole dataset could be used for training (&gt;6 time more data than we used) and the results would be much better.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p class="ltx_p">Experiment with hyperparameters like vocabulary size (we only tried with 10,000 and 20,000), learning rate, learning rate decay, embedding size etc. We saw that our model trained with vocabulary size 20,000 performs better than the one trained with vocabulary size 10,000, maybe increasing it even further will keep upgrading the model.</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p class="ltx_p">If we want the model to perform well not only on legal data, we could build a more complex multi-domain corpus and train on it. The models available on Hugging Face, trained by the organization Helsinki-NLP perform pretty well on the FLORES dataset as well, which makes us think that they were trained on more diverse data.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
      
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
Marcin Junczys-Dowmunt, Roman Grundkiewicz, Tomasz Dwojak, Hieu Hoang, Kenneth Heafield, Tom Neckermann, Frank Seide, Ulrich Germann, Alham Fikri Aji, Nikolay Bogoychev, André F. T. Martins, Alexandra Birch (2018) <a href="https://arxiv.org/abs/1804.00344" title="" class="ltx_ref ltx_href">Marian: Fast Neural Machine Translation in C++</a>

</span>
</li>
      
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(2)</span>
<span class="ltx_bibblock">
Maha Elbayad, Laurent Besacier, Jakob Verbeek (2018) <a href="https://arxiv.org/abs/1808.03867" title="" class="ltx_ref ltx_href">Pervasive Attention: 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction</a>

</span>
</li>
      
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin (2017) <a href="https://arxiv.org/abs/1705.03122" title="" class="ltx_ref ltx_href">Convolutional Sequence to Sequence Learning</a>

</span>
</li>
      
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(4)</span>
<span class="ltx_bibblock">
Hua Wu and Haifeng Wang <a href="https://aclanthology.org/P09-1018.pdf" title="" class="ltx_ref ltx_href">Revisiting Pivot Language Approach for Machine Translation</a>

</span>
</li>
      
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(5)</span>
<span class="ltx_bibblock">
Yichong Leng, Xu Tan, Tao Qin, Xiang-Yang Li, Tie-Yan Liu (2019) <a href="https://arxiv.org/abs/1906.02461" title="" class="ltx_ref ltx_href">Unsupervised Pivot Translation for Distant Languages</a>

</span>
</li>
      
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(6)</span>
<span class="ltx_bibblock">
Bogdan Babych, Anthony Hartley, Serge Sharoff <a href="https://aclanthology.org/2007.mtsummit-papers.5.pdf" title="" class="ltx_ref ltx_href">Translating from under-resourced languages: Comparing direct transfer against pivot translation</a>

</span>
</li>
      
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(7)</span>
<span class="ltx_bibblock">
Ilya Sutskever, Oriol Vinyals, Quoc V. Le (2014) <a href="https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf" title="" class="ltx_ref ltx_href">Sequence to Sequence Learning with Neural Networks</a>

</span>
</li>
      
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(8)</span>
<span class="ltx_bibblock">
Kunjin Chen, Qin Wang, Ziyu He, Kunlong Chen, Jun Hu, Jinliang He (2018) <a href="https://doi.org/10.1049/joe.2018.8352" title="" class="ltx_ref ltx_href">Convolutional sequence to sequence non-intrusive load monitoring</a>

</span>
</li>
      
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, Yoav Artzi (2019) <a href="https://arxiv.org/abs/1904.09675" title="" class="ltx_ref ltx_href">BERTScore: Evaluating Text Generation with BERT</a>

</span>
</li>
    
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  by <a href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>
</body>
</html>

```
@techreport{nlpunibuc-2022-mt-genderbias,
    author = "Dumitrescu Teodor and Sava Daniel",
    title = "Machine Translation Hungarian to Romanian",
    year = "2023",
    month = May,
    url = "https://nlp.unibuc.ro/machine_translation/22_23/hu_ro",
    editor = "lect. dr. Sergiu Nisioi",
    organization = "University of Bucharest",
    publisher = "Machine Translation Series",
    note = "Machine Translation Research Group - Online access."
}
```
